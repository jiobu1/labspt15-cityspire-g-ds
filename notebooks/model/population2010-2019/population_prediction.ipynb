{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd02419ad2920cdc1fadb8f0ae6c1b14e969f8d411f4ecfa904fb0f4ff9d9e2f541",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Population forecasting\n",
    "\n",
    "1. Clean population dataframe\n",
    "2. Transform dataframe\n",
    "3. Forecast population using **fb prophet**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Clean population dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jisha/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('metropop_2010_2019.csv')"
   ]
  },
  {
   "source": [
    "### Check population csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(415, 14)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Metro-Area State    Census  Estimate Base      2010      2011  \\\n",
       "0                  Abilene    TX  165252.0       165252.0  165585.0  166634.0   \n",
       "1                    Akron    OH  703200.0       703196.0  703031.0  703200.0   \n",
       "2                   Albany    GA  153857.0       154033.0  154145.0  154545.0   \n",
       "3           Albany-Lebanon    OR  116672.0       116681.0  116891.0  118164.0   \n",
       "4  Albany-Schenectady-Troy    NY  870716.0       870713.0  871082.0  872778.0   \n",
       "\n",
       "       2012      2013      2014      2015      2016      2017      2018  \\\n",
       "0  167442.0  167473.0  168342.0  169688.0  170017.0  170429.0  171150.0   \n",
       "1  702109.0  703621.0  704908.0  704382.0  703524.0  703987.0  703855.0   \n",
       "2  153976.0  152667.0  151949.0  150387.0  149137.0  148090.0  147840.0   \n",
       "3  118273.0  118405.0  119042.0  120236.0  122769.0  125035.0  127451.0   \n",
       "4  874698.0  877065.0  878113.0  879085.0  879792.0  882158.0  882263.0   \n",
       "\n",
       "       2019  \n",
       "0  172060.0  \n",
       "1  703479.0  \n",
       "2  146726.0  \n",
       "3  129749.0  \n",
       "4  880381.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metro-Area</th>\n      <th>State</th>\n      <th>Census</th>\n      <th>Estimate Base</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abilene</td>\n      <td>TX</td>\n      <td>165252.0</td>\n      <td>165252.0</td>\n      <td>165585.0</td>\n      <td>166634.0</td>\n      <td>167442.0</td>\n      <td>167473.0</td>\n      <td>168342.0</td>\n      <td>169688.0</td>\n      <td>170017.0</td>\n      <td>170429.0</td>\n      <td>171150.0</td>\n      <td>172060.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Akron</td>\n      <td>OH</td>\n      <td>703200.0</td>\n      <td>703196.0</td>\n      <td>703031.0</td>\n      <td>703200.0</td>\n      <td>702109.0</td>\n      <td>703621.0</td>\n      <td>704908.0</td>\n      <td>704382.0</td>\n      <td>703524.0</td>\n      <td>703987.0</td>\n      <td>703855.0</td>\n      <td>703479.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albany</td>\n      <td>GA</td>\n      <td>153857.0</td>\n      <td>154033.0</td>\n      <td>154145.0</td>\n      <td>154545.0</td>\n      <td>153976.0</td>\n      <td>152667.0</td>\n      <td>151949.0</td>\n      <td>150387.0</td>\n      <td>149137.0</td>\n      <td>148090.0</td>\n      <td>147840.0</td>\n      <td>146726.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albany-Lebanon</td>\n      <td>OR</td>\n      <td>116672.0</td>\n      <td>116681.0</td>\n      <td>116891.0</td>\n      <td>118164.0</td>\n      <td>118273.0</td>\n      <td>118405.0</td>\n      <td>119042.0</td>\n      <td>120236.0</td>\n      <td>122769.0</td>\n      <td>125035.0</td>\n      <td>127451.0</td>\n      <td>129749.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albany-Schenectady-Troy</td>\n      <td>NY</td>\n      <td>870716.0</td>\n      <td>870713.0</td>\n      <td>871082.0</td>\n      <td>872778.0</td>\n      <td>874698.0</td>\n      <td>877065.0</td>\n      <td>878113.0</td>\n      <td>879085.0</td>\n      <td>879792.0</td>\n      <td>882158.0</td>\n      <td>882263.0</td>\n      <td>880381.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(population.shape)\n",
    "population.head()"
   ]
  },
  {
   "source": [
    "### Combine city state\n",
    "- use explode to separate combined cities\n",
    "- combine separated city and states"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_str(population, col='Metro-Area', sep='-'):\n",
    "    s = population[col]\n",
    "    i = np.arange(len(s)).repeat(s.str.count(sep) +1)\n",
    "    return population.iloc[i].assign(**{col: sep.join(s).split(sep)})\n",
    "\n",
    "population = explode_str(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['Metro-Area'] = population['Metro-Area'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['City,State'] = population['Metro-Area'] + ', ' + population['State']"
   ]
  },
  {
   "source": [
    "### Drop unused columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = population.drop(columns = ['Census', 'Estimate Base', 'Metro-Area', 'State'])\n",
    "population = population[['City,State', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(654, 11)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    City,State      2010      2011      2012      2013      2014      2015  \\\n",
       "0  Abilene, TX  165585.0  166634.0  167442.0  167473.0  168342.0  169688.0   \n",
       "1    Akron, OH  703031.0  703200.0  702109.0  703621.0  704908.0  704382.0   \n",
       "2   Albany, GA  154145.0  154545.0  153976.0  152667.0  151949.0  150387.0   \n",
       "3   Albany, OR  116891.0  118164.0  118273.0  118405.0  119042.0  120236.0   \n",
       "3  Lebanon, OR  116891.0  118164.0  118273.0  118405.0  119042.0  120236.0   \n",
       "\n",
       "       2016      2017      2018      2019  \n",
       "0  170017.0  170429.0  171150.0  172060.0  \n",
       "1  703524.0  703987.0  703855.0  703479.0  \n",
       "2  149137.0  148090.0  147840.0  146726.0  \n",
       "3  122769.0  125035.0  127451.0  129749.0  \n",
       "3  122769.0  125035.0  127451.0  129749.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City,State</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abilene, TX</td>\n      <td>165585.0</td>\n      <td>166634.0</td>\n      <td>167442.0</td>\n      <td>167473.0</td>\n      <td>168342.0</td>\n      <td>169688.0</td>\n      <td>170017.0</td>\n      <td>170429.0</td>\n      <td>171150.0</td>\n      <td>172060.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Akron, OH</td>\n      <td>703031.0</td>\n      <td>703200.0</td>\n      <td>702109.0</td>\n      <td>703621.0</td>\n      <td>704908.0</td>\n      <td>704382.0</td>\n      <td>703524.0</td>\n      <td>703987.0</td>\n      <td>703855.0</td>\n      <td>703479.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albany, GA</td>\n      <td>154145.0</td>\n      <td>154545.0</td>\n      <td>153976.0</td>\n      <td>152667.0</td>\n      <td>151949.0</td>\n      <td>150387.0</td>\n      <td>149137.0</td>\n      <td>148090.0</td>\n      <td>147840.0</td>\n      <td>146726.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albany, OR</td>\n      <td>116891.0</td>\n      <td>118164.0</td>\n      <td>118273.0</td>\n      <td>118405.0</td>\n      <td>119042.0</td>\n      <td>120236.0</td>\n      <td>122769.0</td>\n      <td>125035.0</td>\n      <td>127451.0</td>\n      <td>129749.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lebanon, OR</td>\n      <td>116891.0</td>\n      <td>118164.0</td>\n      <td>118273.0</td>\n      <td>118405.0</td>\n      <td>119042.0</td>\n      <td>120236.0</td>\n      <td>122769.0</td>\n      <td>125035.0</td>\n      <td>127451.0</td>\n      <td>129749.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(population.shape)\n",
    "population.head()"
   ]
  },
  {
   "source": [
    "## 2. Stack dataframe \n",
    "- this is to try the groupby so I don't have to create separate csv's and run each city csv separately\n",
    "- https://stackoverflow.com/questions/64179626/stack-unstack-melt-pivot-transpose-what-is-the-simple-method-to-convert-mul"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_melt = (population.melt(id_vars=['City,State'],\n",
    "                    var_name = 'ds',\n",
    "                    value_name = 'y'\n",
    "                    ).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_melt"
   ]
  },
  {
   "source": [
    "## 3. Forecast population using **fb prophet**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = population_melt.groupby('City,State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:fbprophet:n_changepoints greater than number of observations. Using 7.\n",
      "INFO:fbprophet:n_changepoints greater than number of observations. Using 15.\n"
     ]
    }
   ],
   "source": [
    "for g in grouped.groups:\n",
    "    group = grouped.get_group(g)\n",
    "    m = Prophet()\n",
    "    m.fit(group)\n",
    "    print(group)\n",
    "    future = m.make_future_dataframe(periods=10, freq='Y')\n",
    "    forecast = m.predict(future)\n",
    "    forecast = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    forecast = forecast.rename(columns={'yhat': 'yhat_'+g, \n",
    "                                        'yhat_lower': 'yhat_lower_'+g,\n",
    "                                        'yhat_upper': 'yhat_upper_'+g})\n",
    "    final = pd.merge(final, forecast.set_index('ds'), how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[['yhat_'+g, 'yhat_lower_'+g, 'yhat_upper_'+g for g in grouped.groups.keys()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ]
  }
 ]
}