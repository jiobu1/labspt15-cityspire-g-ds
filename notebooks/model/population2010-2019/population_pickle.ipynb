{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python386jvsc74a57bd02419ad2920cdc1fadb8f0ae6c1b14e969f8d411f4ecfa904fb0f4ff9d9e2f541",
      "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
    },
    "colab": {
      "name": "population_pickle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.6"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikh_Fb86pCnj"
      },
      "source": [
        "# Create Prediction Forecast Endpointd\n",
        "1. Load CSV \n",
        "2. Create and Test Pickle\n",
        "3. Create Prediction Function\n",
        "4. Create Visualization Function\n",
        "5. Test Prediction and Visualization Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1QKq92WpCoZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from fbprophet import Prophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## 1. Load CSV"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39GoJs9GpCoc"
      },
      "source": [
        "population_melt = pd.read_csv('https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_melt.csv')\n",
        "population = pd.read_csv('https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_cleaned.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## 2. Create and Test Pickle\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Create a dictionary\n",
        "- zip city list\n",
        "- create a list of grouped dataframe"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cities_list = list(population['City,State'])"
      ]
    },
    {
      "source": [
        "### Fit FB Prophet model\n",
        "- fit model on dataframe\n",
        "- create multiple models \n",
        "- pickle models \n",
        "\n",
        "was unable to complete this process. The model took too long to even pickle for it to be useful as a model. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Fit model on DataFrame"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_model(start:0, end:100):\n",
        "  cities_list = list(population['City,State'])[start:end]\n",
        "\n",
        "  models = []\n",
        "  for city_name in cities_list:\n",
        "      df_ = population_melt[population_melt['City,State'] == city_name]\n",
        "      m = Prophet(interval_width=0.95)\n",
        "      model = m.fit(df_)\n",
        "      models.append([city_name, model])\n",
        "\n",
        "  # Putting information into dataframe\n",
        "  model_df = pd.DataFrame(models, columns = [\"cityname\", 'model'])\n",
        "  return model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_0_100 = make_model(0, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_101_200 = make_model(101, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_201_300 = make_model(201, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_301_400 = make_model(301, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_401_500 = make_model(401, 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_501_600 = make_model(501, 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_601_700 = make_model(601, 700)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_701_730 = make_model(701, 730)"
      ]
    },
    {
      "source": [
        "### Create pickle of models"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create list of models\n",
        "model_list = [model_0_100, \n",
        "              model_101_200, \n",
        "              model_201_300, \n",
        "              model_301_400, \n",
        "              model_401_500, \n",
        "              model_601_700, \n",
        "              model_701_730]\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "    with open(f'pickle/str{model_list[i]}', 'wb') as mod:\n",
        "        pickle.dump(model_list[i], mod)"
      ]
    },
    {
      "source": [
        "### Open Models"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the models\n",
        "df_100 = pickle.load(open(\"pickle/model_0_100.pkl\", 'rb'))\n",
        "df_200 = pickle.load(open(\"pickle/model_101_200.pkl\", 'rb'))\n",
        "df_300 = pickle.load(open(\"pickle/model_201_300.pkl\", 'rb'))\n",
        "df_400 = pickle.load(open(\"pickle/model_301_400.pkl\", 'rb'))\n",
        "df_500 = pickle.load(open(\"pickle/model_401_500.pkl\", 'rb'))\n",
        "df_600 = pickle.load(open(\"pickle/model_501_600.pkl\", 'rb'))\n",
        "df_700 = pickle.load(open(\"pickle/model_601_700.pkl\", 'rb'))\n",
        "df_730 = pickle.load(open(\"pickle/model_701_730.pkl\", 'rb'))\n",
        "\n",
        "# Concatenate the dataframes of zip codes/model\n",
        "model_df_all= pd.concat([df_100, df_200, df_300, df_400, df_500, df_600, df_700, df_730])"
      ]
    },
    {
      "source": [
        "### Serializing with json"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python\n",
        "import json\n",
        "from fbprophet.serialize import model_to_json, model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(model_list)):\n",
        "    with open('serialized_model.json', 'w') as fout:\n",
        "        json.dump(model_to_json(model_list), fout)  # Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('serialized_model.json', 'r') as fin:\n",
        "    all_models = model_from_json(json.load(fin))  # Load model"
      ]
    },
    {
      "source": [
        "## 3. Create Prediction and Visualization Function"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this model works but just locally\n",
        "def population_forecast(city, periods):\n",
        "    # Load Dataset\n",
        "  population = pd.read_csv('https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_cleaned.csv')\n",
        "  population.reset_index(level=0, inplace=True)\n",
        "\n",
        "  # Melt table into ds and y\n",
        "  population_melt = population[['City,State', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]\n",
        "  population_melt = population_melt.melt(id_vars=['City,State'], var_name='ds', value_name='y')\n",
        "\n",
        "  # Isolate city data\n",
        "  city = [city]\n",
        "  df_ = population_melt.loc[population_melt['City,State'].isin(city)][['ds', 'y']]\n",
        "  print(df_)\n",
        "  df_.columns = ['ds','y']\n",
        "\n",
        "  # Fit and Predict on city dataframe\n",
        "  # m = Prophet(interval_width=0.95)\n",
        "  m.fit(df_)\n",
        "  future = m.make_future_dataframe(periods=periods, freq='Y')\n",
        "  forecast = m.predict(future)\n",
        "  predictions = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']][9:]\n",
        "  predictions['ds'] = predictions['ds'].dt.year\n",
        "  print(predictions['ds'])\n",
        "  predictions[['yhat', 'yhat_lower', 'yhat_upper']] =  predictions[['yhat', 'yhat_lower', 'yhat_upper']].round()\n",
        "  print(predictions.tail())\n",
        "\n",
        "  # Create graph\n",
        "  # Graph first 10 years\n",
        "  df_['ds'] = df_['ds'].astype(int)\n",
        "  ax = df_.plot(x = 'ds', y = 'y', label='Observed', figsize= (10, 8)) \n",
        "\n",
        "  # Graph predictions including the upper and lower bounds\n",
        "  predictions['ds'] = predictions['ds'].astype(int)\n",
        "  predictions[['ds', 'yhat']].plot(ax = ax, x = 'ds', y = 'yhat', label = \"Forecast\") \n",
        "  ax.fill_between(predictions['ds'],\n",
        "                predictions['yhat_lower'],\n",
        "                predictions['yhat_upper'],\n",
        "                color='k', \n",
        "                alpha=.25)\n",
        "\n",
        "  ax.set_xlabel('Year')\n",
        "  ax.set_ylabel('Population')\n",
        "  plt.title(f\"{city[0]} Population\" )\n",
        "  plt.legend()\n",
        "\n",
        "  return plt.show()"
      ]
    },
    {
      "source": [
        "## 4. Create Visualization Function\n",
        "- using saved predictions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "POPULATION_CSV = 'https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_cleaned.csv'\n",
        "FORECAST_CSV = 'https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_prediction.csv'\n",
        "\n",
        "def get_plot(city):\n",
        "  city = [city]\n",
        "\n",
        "  # Historical population data\n",
        "  population = pd.read_csv(POPULATION_CSV)\n",
        "  population = population[population['City,State'].isin(city)]\n",
        "  population = population[['City,State', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]\n",
        "  population_melt = population.melt(id_vars=['City,State'], var_name='ds', value_name='y')\n",
        "  population_melt['ds'] = population_melt['ds'].astype(int)\n",
        "\n",
        "  # Predictions\n",
        "  forecast = pd.read_csv(FORECAST_CSV)\n",
        "  df = forecast[forecast['City,State'].isin(city)][9:]\n",
        "  df['year'] = df['year'].astype(int)\n",
        "\n",
        "  # Graph Data\n",
        "  ax = population_melt.plot(x = 'ds', y = 'y', label='Observed', figsize= (10, 8))\n",
        "  df[['year', 'yhat']].plot(ax = ax, x = 'year', y = 'yhat', label = \"Forecast\")\n",
        "\n",
        "  # Fill to show upper and lower bounds\n",
        "  ax.fill_between(df['year'],\n",
        "                df['yhat_lower'],\n",
        "                df['yhat_upper'],\n",
        "                color='k', \n",
        "                alpha=.25)\n",
        "\n",
        "  ax.set_xlabel('Year')\n",
        "  ax.set_ylabel('Population')\n",
        "  plt.title(f\"{city[0]} Population\" )\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# @router.post('/api/population_forecast')\n",
        "# def population_forecast(city:City, periods=10):\n",
        "#     \"\"\"\n",
        "#     Create visualization of historical and forecasted population\n",
        "\n",
        "#     args:\n",
        "#     - city: str -> The target city\n",
        "#     - periods: int -> number of years to forecast for\n",
        "\n",
        "#     Returns:\n",
        "#     Visualization of population forecast\n",
        "#     - 10 year of historical data\n",
        "#     - forecasts for number of years entered\n",
        "#     \"\"\"\n",
        "\n",
        "#     city = validate_city(city)\n",
        "\n",
        "#     # Load Dataset\n",
        "#     population = pd.read_csv('https://raw.githubusercontent.com/jiobu1/labspt15-cityspire-g-ds/main/notebooks/model/population2010-2019/csv/population_cleaned.csv')\n",
        "#     population.reset_index(level=0, inplace=True)\n",
        "\n",
        "#     # Melt table into ds and y\n",
        "#     population_melt = population[['City,State', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]\n",
        "#     population_melt = population_melt.melt(id_vars=['City,State'], var_name='ds', value_name='y')\n",
        "\n",
        "#     # Isolate city data\n",
        "#     location = [city.city + ', ' + city.state]\n",
        "#     df_ = population_melt.loc[population_melt['City,State'].isin(location)][['ds','y']]\n",
        "#     df_.columns = ['ds','y']\n",
        "\n",
        "\n",
        "#     # Fit and Predict on city dataframe\n",
        "#     # Model\n",
        "#     with open(\"app/data/pickle_model/model.pkl\", \"rb\") as f:\n",
        "#         m = load(f)\n",
        "#     m = Prophet(interval_width=0.95)\n",
        "\n",
        "#     # Fit model\n",
        "#     m.fit(df_)\n",
        "#     future = m.make_future_dataframe(periods=periods, freq='Y')\n",
        "\n",
        "#     # Predict\n",
        "#     forecast = m.predict(future)\n",
        "#     predictions = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']][9:]\n",
        "#     predictions['ds'] = pd.DatetimeIndex(predictions['ds']).year\n",
        "#     predictions[['yhat', 'yhat_lower', 'yhat_upper']] =  predictions[['yhat', 'yhat_lower', 'yhat_upper']].round()\n",
        "\n",
        "#     # Create graph\n",
        "#     # Graph first 10 years\n",
        "#     df_['ds'] = df_['ds'].astype(int)\n",
        "#     predictions['ds'] = predictions['ds'].astype(int)\n",
        "\n",
        "#     # Graph historical data\n",
        "#     fig = go.Figure()\n",
        "\n",
        "#     fig.add_trace(go.Scatter(\n",
        "#         name = 'Original',\n",
        "#         x = list(df_['ds']),\n",
        "#         y = list(df_['y']),\n",
        "#         fill = None,\n",
        "#         mode = 'lines',\n",
        "#         line_color = 'black',\n",
        "#         showlegend = True\n",
        "#     ))\n",
        "\n",
        "#     # Graph predictions including the upper and lower bounds\n",
        "#     fig.add_trace(go.Scatter(\n",
        "#         name = 'Forecast',\n",
        "#         x = list(predictions['ds']),\n",
        "#         y = list(predictions['yhat']),\n",
        "#         fill = None,\n",
        "#         mode = 'lines',\n",
        "#         line_color = 'red',\n",
        "#         showlegend = True\n",
        "#     ))\n",
        "\n",
        "#     fig.add_trace(go.Scatter(\n",
        "#         name = 'Lower Bound',\n",
        "#         x = list(predictions['ds']),\n",
        "#         y = list(predictions['yhat_lower']),\n",
        "#         fill = None,\n",
        "#         mode = 'lines',\n",
        "#         line_color = 'gray',\n",
        "#     ))\n",
        "\n",
        "#     fig.add_trace(go.Scatter(\n",
        "#         name = 'Upper Bound',\n",
        "#         x = list(predictions['ds']),\n",
        "#         y = list(predictions['yhat_upper']),\n",
        "#         fill='tonexty',\n",
        "#         mode='lines',\n",
        "#         line_color = 'gray',\n",
        "#     ))\n",
        "\n",
        "#     # Edit the layout\n",
        "#     fig.update_layout({\n",
        "#         'autosize':True,\n",
        "#         'title': f'{city[0]} Population Forecast',\n",
        "#         'title_x': 0.5,\n",
        "#         'xaxis_title': 'Year',\n",
        "#         'yaxis_title': 'Population'\n",
        "#         })\n",
        "\n",
        "#     fig.update_yaxes(automargin = True,)\n",
        "#     fig.update_xaxes(automargin = True, nticks=20)\n",
        "\n",
        "#     fig.show()\n",
        "\n",
        "#     return fig.to_json"
      ]
    }
  ]
}